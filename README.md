Regularized Logistic regression using gradient descent : serial, parallel and map reduce implementation

Implementation details available in respective directories. 

NOTE: Serial and parallel implementation are basic implementation and will be very slow compared to logistic regression implementation available in scikit-learn because I have not used any compiled optimized libraries.

Goal of this was to understand performance difference between serial, parallel and distributed implementation of algorithms, so relatively these three performed well as expected but these implementations can't be compared with any other well known library implementation. 

